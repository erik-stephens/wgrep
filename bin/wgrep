#! /usr/bin/env python
"""
A grep-like utility for common crawl files using a jquery-like api (pyquery).

Usage: wgrep {<expressions>}

  - expression: one or more expressions to search for & report on
    - a path to a python function (eg pkg.module.method), or
    - a special path `page` and attribute (eg `page.url`, see `wgrep.Page`)

Pages are read from stdin and need to be in common crawl format:

  see https://s3.amazonaws.com/cc_example_data/com.searchengineland/29736.gz
"""

import os
import sys
from importlib import import_module
from functools import partial
from collections import namedtuple
from pyquery import PyQuery
from wgrep import pages, Page


if sys.version_info.major < 3:
    # For maximal interop, normalize strings to non-unicode.
    def U(s):
        if isinstance(s, unicode):
            s = s.encode('utf')
        return s
else:
    def U(s):
        return s

DELIM = os.environ.get('DELIM', '\t')

Expr = namedtuple('Expr', ['name', 'func'])


def page_attr(attr, page, pyqry):
    return getattr(page, attr)


def main(fInput, *methods):
    # Prepare all requested expressions.
    exprs = []
    for method_path in methods:
        module, attr = method_path.rsplit('.', 1)
        if module == 'page' and hasattr(Page, attr):
            expr = Expr(attr, partial(page_attr, attr))
        else:
            module = import_module(module)
            expr = Expr(attr, getattr(module, attr))
        exprs.append(expr)

    # Evaluate & report expressions for each page
    for page in pages(fInput):
        if 'html' not in page.content_type:
            continue
        pyqry = PyQuery(''.join(page.body))
        cols = []
        for expr in exprs:
            cols.append(U(expr.func(page, pyqry)))
        print(DELIM.join(i for i in cols))


if __name__ == '__main__':
    if len(sys.argv) < 2:
        sys.stderr.write(__doc__)
        sys.exit(2)
    main(sys.stdin, *sys.argv[1:])
